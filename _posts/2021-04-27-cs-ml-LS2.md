---
layout: post
title: "Lecture Summary 2"
subtitle: "DL programming & CNN"
categories: cs
tags: ml
comments: true  
# header-img: img/review/review-book-organize-thoughts-1.png

---
> `AI Application System` 강의 중 week 5~7 내용 정리입니다.

### Deep Learning Software

Compuational Graphs : Comput Gradient

Numpy

- 장점 : 직관적임. 코드 작성이 쉬움
- 단점 : Back Propagation을 통해 Gradient 계산식을 구해야함, GPU로 연산 불가

PyTorch

- 장점 : Gradient를 쉽게 구할 수 있음, GPU 연산 가능

---

PyTorch

Numpy와 같이 array 단위로 데이터를 관리하여 연산. But GPU로 실행 가능

Forward pass : loss 계산

Backward pass : gradient 계산

Autograd : gradients의 자동 연산

- torch.randn(D1, D2, requires_grad=True)로 Autograd 활성화
- loss.backward()를 통해 자동으로 Backward Pass 수행
- w1.grad, w2.grad로 gradient 호출.
- 사용후, w1.grad.zero_()로 값 해제

torch.nn.Sequential()로 여러개의 function을 묶어서 사용할수 있음

torch.nn.funtional.~에서 이미 정의된 loss function을 간편하게 사용 가능

torch.optim.~에서 이미 정의된 optimizer 사용 가능

- optimizer = torch.optim.~()로 선언
- optimizer.step()으로 optimizer로 값 update

Module : 학습 가능한 weight를 저장하는 neural network layer

### Convolutional Neural Networks

fully connected layer : 공간상의 정보를 포함하지 않는 1차원 벡터. 

- nubmer of parameters : 1차원 벡터의 원소 개수

Convolution layer : 공간상의 정보를 유지하는 2차원 map

- Filter : Convolution을 수행하기 위해 input에 적용. filter depth = input depth
- fully connected layer보다 parameter의 개수가 현저히 감소

    nubmer of parameters : (filter Width * filter Height * filter depth +1***(Bias)***) * filter 개수

- activation maps : filter를 이동시키며 input image의 모든 영역에서 convolution한 결과

    activation maps의 depth는 filter의 개수,  

Pooling layer

- Network가 깊어질수록 activation maps의 depth도 깊어짐 → parameter 개수 증가
- 이를 해소하기 위한 공간적인 down sampling.
- Max Pooling : 정석적인 방법

    filter 내부의 최대값을 output으로 선택

    nubmer of parameters : 0

---

Output size

- input보다 항상 size가 감소함. (input - filter) / stride + 1

    stride : 얼마나 shift하며 slide 할지

- zero padding : output size의 감소를 방지 하기 위해 바깥 영역을 zero로 채움. 공간적 사이즈 유지

    이때의 ouput size = (input +2pad - filter) / stride + 1 

1x1 convolution layer 사용의 이유 : filter개수를 조절하여 차원 축소 / 확정을 고려함.

### CNN Architectures

LeNet-5

5x5 Conv filter를 stride 1로 convolution , 2x2 stride 2 pooling으로 subsampling(down sampling)

CONV → POOL → COMV → POOL → FC → FC

---

ILSVRC

AlexNet : 8 layers. 최초의 CNN-based 우승자

ZFNet : 8 layers. AlexNet을 기반으로 hyperparameter tuning을 통해 성능 향상

VGGNet : 19 layers. filter size를 감소시켜, 더 깊은 network를 구현함

![/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled.png](/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled.png)

3x3 filter*3은 7x7 filter와 같은 effective receptive field를 갖는다.

필터사이즈↓ 필터개수↑ → network 깊어짐 → activation function개수 증가 → 비 선형성 증가

파라미터 개수 감소, But Convolution layer 이후 FC layer로 변경하며 parameter 개수가 급격히 증가하는것은 해결하지 못함

메모리 효율 나쁨

- GoogLeNet : 22 layers. Inception module을 이용하여 parameter를 줄임

    ![/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%201.png](/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%201.png)

    Inception Module : 같은 층의 레이어에서 여러 사이즈의 컨볼루션 커널 사용

    컨볼루션 레이어가 여러개 사용되어 늘어나는 파라미터 개수를, 1x1 컨볼루션 레이어를 통해 차원을 감소시켰다.

    ![/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%202.png](/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%202.png)

    global average pooling : FC layer이전에 1x1xc을 이용하여 파리미터의 개수를 감소시킴

    Auxiliary classification 

    ![/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%203.png](/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%203.png)

    Back Propagation 특성상 레이어가 깊어질수록 gradient가 잘 전달되지 않을수 있음(vanishing gradient)

    → 중간중간 softmax를 두어 중간에서도 back propagation을 수행함(Auxiliary classification)

    트레이닝 시에만 사용, 테스트 시에는 사용 x

    ---

- ResNet : 152 layers. residual connection(skip connection)을 이용한 매우 깊은 network

    기존 네트워크는 깊을수록 optimization이 어려워져 학습결과가 나빠졌다.

    Residual Block 

    입력 레이어에서 x를 가져와 Conv된 결과 F(x)에 더해준다. 즉 H(x) = F(x) + x

    F(x) = H(x) - x 에 대해 학습을 수행하며, F(x)가 0이 되도록 학습한다.

    이렇게 하면 입력의 잔차(residual)을 학습할 수 있다.

### Fancier CNN Architectures

ResNet 기반 발전

- Identity Mappings in Deep Residual Networks : Residual block의 layer 순서를 변경
- Wide Residual Networks : 필터의 개수를 증가시켜, 더 넓은 residual block 사용.

    50-layer wide ResNet이 152-layer original ResNet과 같은 성능을 가짐.

    깊이보다 너비를 증가시키는 것이 병렬 연산이 가능하여 더 효율적.

- ResNeXt : Inception 모듈과 같이 같은 층에서 여러개의 layer를 이용해 병렬 처리.
- DenseNet : 모든 layer를 연결한 dense block을 사용한다.

    50-layer DenseNet는 152-layer ResNet과 같은 성능을 낼 수 있다. 때문에 파라미터의 개수를 줄일 수 있다.

NAS : 자식 네트워크의 구조를 문자열로 표현하여, 부모 네트워크가 이를 학습시킨다.

### Different Types of Convolutions

![/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%204.png](/assets/img/post_img/2021-04-27-cs-ml-LS2/Untitled%204.png)

Dilated Convolution : 필터 내부에 zero padding을 추가해 receptive field를 늘리는 방법. 

- 일반적인 CNN은 pooling으로 인한 정보 손실이 발생한다.
- Dilated Conv를 이용하면 pooling이 필요하지 않아 spatial dimension의 손실이 적다.

Spatial Separable Convolution : 커널을 두 개의 작은 커널로 나누어 convolution한다. 

- 곱셈 연산의 횟수가 감소하고, parameter의 개수가 감소한다.

Depth-wise Separable Convolution 

- Depth-wise : 각 단일 채널에 대해서만 convolution을 수행하여 다시 결합하는 구조.
- Point-wise : 1x1xc filter
- Depth-wise와 Point-wise를 수행하여 채널의 출력 값을 하나로 합친다. Spatial feature와 Channel-wise Feature를 모두 고려하여 연산을 줄여 경랑화 하는 방법

Grouped Convolution : 입력 값의 채널들을 그룹으로 나누어 독립적으로 Convolution을 수행하여 계산 효율을 높이는 방식

### Semantic Segmentation

Object끼리 판별하지 않고, pixel별로만 판단 - 같은 class의 다수의 object 판별 불가

기본적인 idea : sliding window 의 center pixel에 class를 부여

input과 ouput size가 같아야 하기 때문에, downsampling & upsampling이 필요

Down sampling : Pooling, strided convolution

Up sampling : Unpooling, strided transpose convolution(deconv)

- Unpooling : Nearest neighbor, Bed of Nails
- Max Unpooling : down sampling pooling시 max값의 위치를 기억하고, 같은 level의 up sampling에서 그 위치를 사용
- Traspose Convolution : input에 padding을 많이 넣어서 convolution하여 up sampling하는것.

    convolution parameter가 있어서 학습가능. Learnable upsampling

    But, checker board가 생기는 issue.

그래서 rule-base up sampling(un pooling)을 사용하고, conv를 통해 learnable 하게 하여 보완

### Object Detection & Instance Segmentation

Multiple Object에 대해서 판별 가능

Object Detection 

CNN 이후 Softmax로 classify & linear regression으로 localization한 두개의 loss를 합하여 학습 Multitask Loss

Single Object는 가능, But Multiple Object일 경우 image마다 output의 개수가 다르므로 어려움

Multiple Object Detection

- image를 여러 patch로 잘라서 모두 CNN으로 classify함 - 연산량 매우 많음

    → Region Proposals : 오브젝트를 포함할 것 같은 영역을 제안하여, patch 개수를 줄임

    Selective Search : 비슷한 특성(brightness, sharpness)을 가진 pixel끼리 병합함

- R-CNN : 모든 영역을 보지말고, 일부 영역만 보자
    1. 사용자가 정한 최대 개수만큼의 ROI를 proposal method를통해 얻음
    2. 영역을 Warped
    3. 각 영역을 image classfication ConvNet에 통과시킴
    4. classify & localization

    최대 개수만큼 독립적인 forward pass가 필요하므로 매우느림

- Fast R-CNN : ROI의 개수를 감소시키자
    1. 전체 이미지를 ConvNet에 통과
    2. 통과된 feature map에서 ROI를 cropping → Warp
    3. 각 영역에 대해 shallow CNN을 통과시키고,  classify & localization

    처리 시간은 감소시켰으나, region proposal의 runtime 비율이 너무 큼

- Faster R-CNN : region proposal의 시간을 감소시키자
    1. Backbone 이후 Shallow Region proposal network를 추가함 - 1stage
    2. ROI pool / align
    3. classify & localizations

Cropping Features

- ROI Pool
    1. proposal된 영역을 feature map에 투영
    2. 투영된 영역(실수)이 grid cell(정수)에 맞도록 이동(반올림등) - Snap
    3. 2x2영역으로 rough하게 나눔
    4. 나눠진 sub 영역에서 Max pooling을 통해 region  feature를 얻음

    실수에서 정수로 바꿔서 실제와 약간 차이가 있음

- ROI Align : 차이를 줄여보자
    1. proposal된 영역을 feature map에 투영
    2. Snap하지 않고, 2x2 sub 영역으로 나눔
    3. 정규 지점을 bilinear interpolation으로 추출
    4. 추출된 점을 max pooling하여 region feature얻음 

Instance Segmentatation

Object Detection에 Mask prediction을 더하여 instance와 background를 분리함

---